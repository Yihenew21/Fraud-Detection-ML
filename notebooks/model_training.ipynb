{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b60c2a8",
   "metadata": {},
   "source": [
    "# Task 2: Model Building and Training\n",
    "\n",
    "This notebook builds and evaluates machine learning models (Logistic Regression and Random Forest) for fraud detection, addressing class imbalance with SMOTE, and incorporating normalization and categorical encoding.\n",
    "\n",
    "## Objectives\n",
    "- Preprocess data for modeling (SMOTE, scaling, encoding).\n",
    "- Train and evaluate Logistic Regression and Random Forest models.\n",
    "- Report performance metrics (accuracy, precision, recall, F1-score, ROC-AUC).\n",
    "\n",
    "## Datasets\n",
    "- `processed_ecommerce.csv`: Cleaned e-commerce data from Task 1.\n",
    "- `processed_creditcard.csv`: Cleaned credit card data from Task 1.\n",
    "\n",
    "## Setup\n",
    "- Run in the same virtual environment with dependencies from `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b492e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from src.data_utils import load_data\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Load processed datasets\n",
    "ecommerce_df = load_data('data/processed/processed_ecommerce.csv')\n",
    "creditcard_df = load_data('data/processed/processed_creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34b53c",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Apply SMOTE to balance classes.\n",
    "- Normalize numerical features.\n",
    "- Encode categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27bd771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "features = ['purchase_value', 'time_since_signup', 'hour_of_day', 'day_of_week', 'source', 'browser', 'country']\n",
    "target = 'class'\n",
    "\n",
    "# Separate features and target for e-commerce data\n",
    "X = ecommerce_df[features]\n",
    "y = ecommerce_df[target]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_cols = ['source', 'browser', 'country']\n",
    "num_cols = ['purchase_value', 'time_since_signup', 'hour_of_day', 'day_of_week']\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_train_cat = encoder.fit_transform(X_train[cat_cols])\n",
    "X_test_cat = encoder.transform(X_test[cat_cols])\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_num = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Combine numerical and categorical features\n",
    "X_train_processed = np.hstack((X_train_num, X_train_cat))\n",
    "X_test_processed = np.hstack((X_test_num, X_test_cat))\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "print('Original train set shape:', X_train_processed.shape)\n",
    "print('Resampled train set shape:', X_train_res.shape)\n",
    "print('Class distribution after SMOTE:', np.bincount(y_train_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329979eb",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "- Train Logistic Regression and Random Forest.\n",
    "- Evaluate with metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca806a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Train models\n",
    "lr_model.fit(X_train_res, y_train_res)\n",
    "rf_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict\n",
    "y_pred_lr = lr_model.predict(X_test_processed)\n",
    "y_pred_rf = rf_model.predict(X_test_processed)\n",
    "\n",
    "# Evaluate metrics\n",
    "metrics_lr = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "    'precision': precision_score(y_test, y_pred_lr),\n",
    "    'recall': recall_score(y_test, y_pred_lr),\n",
    "    'f1': f1_score(y_test, y_pred_lr),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_lr)\n",
    "}\n",
    "metrics_rf = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'precision': precision_score(y_test, y_pred_rf),\n",
    "    'recall': recall_score(y_test, y_pred_rf),\n",
    "    'f1': f1_score(y_test, y_pred_rf),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_rf)\n",
    "}\n",
    "\n",
    "print('Logistic Regression Metrics:', metrics_lr)\n",
    "print('Random Forest Metrics:', metrics_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32d80f",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Optimize hyperparameters using GridSearchCV.\n",
    "- Generate ROC curves for visualization.\n",
    "- Prepare Interim-2 report with detailed analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
